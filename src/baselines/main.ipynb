{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from time import sleep\n",
    "import nltk\n",
    "import numpy as np\n",
    "import argparse\n",
    "from langchain.llms import OpenAI\n",
    "import baseline_utils\n",
    "from dotenv import load_dotenv\n",
    "from types import SimpleNamespace\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = baseline_utils.create_prompt_template('0cot_gsm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSM_Answer(BaseModel):\n",
    "    work: str = Field(description=\"Explanation of answer\")\n",
    "    final_answer: str = Field(description=\"Final numeric answer\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=GSM_Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': '../../data/gsm_data',\n",
    "    'save_dir': 'models',\n",
    "    'debug': False,\n",
    "    'exp_label': 'default',\n",
    "    'task': '0cot_gsm',\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'max_tokens': 2048,\n",
    "    'temperature': 0.0,\n",
    "}\n",
    "args['ckpt_path'] = os.path.join(args['save_dir'], args['exp_label'])\n",
    "args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = baseline_utils.Logger(os.path.join(args.ckpt_path, 'log.txt'))\n",
    "completed_rounds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_generate_answer(llm, prompt_template, problem):\n",
    "    inp = prompt_template.format(context = problem['context'], format_instructions=parser.get_format_instructions())\n",
    "    # print(inp)\n",
    "    success = False\n",
    "    while not success:\n",
    "      try:\n",
    "        output = await llm.agenerate([inp])\n",
    "        print(output)\n",
    "        success = True\n",
    "      except Exception as e:\n",
    "        logger.write(e)\n",
    "        logger.write(f'API server overloaded. Waiting for 30 seconds...')\n",
    "        sleep(30)\n",
    "        continue\n",
    "    problem['output'] = output.generations[0][0].text\n",
    "    global completed_rounds\n",
    "    completed_rounds += 1\n",
    "    print(f\"Completed {completed_rounds} rounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_generate_answers(llm, prompt_template, problems):\n",
    "  '''Generate the answer for the given problem.'''\n",
    "  outputs = [async_generate_answer(llm, prompt_template, prob) for prob in problems]\n",
    "  await asyncio.gather(*outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(llm, prompt_template, problem):\n",
    "    inp = prompt_template.format(context = problem['context'], format_instructions=parser.get_format_instructions())\n",
    "    # print(inp)\n",
    "    success = False\n",
    "    while not success:\n",
    "      try:\n",
    "        output = llm.generate([inp])\n",
    "        print(output)\n",
    "        success = True\n",
    "      except Exception as e:\n",
    "        logger.write(e)\n",
    "        logger.write(f'API server overloaded. Waiting for 30 seconds...')\n",
    "        sleep(30)\n",
    "        continue\n",
    "    problem['output'] = output.generations[0][0].text\n",
    "    global completed_rounds\n",
    "    completed_rounds += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(llm, prompt_template, problems):\n",
    "    for prob in problems:\n",
    "        generate_answer(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gsm_run(prompt_template, llm, data):\n",
    "    global completed_rounds\n",
    "    completed_rounds = 0\n",
    "    problems = [{'context': d['input'], 'target': d['target']} for d in data]\n",
    "    step = 10\n",
    "    for i in range(0, len(problems), step):\n",
    "        await async_generate_answers(llm, prompt_template, problems[i:min(i + step, len(problems))])\n",
    "        print (f\"Completed {i + step} problems\")\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(problems):\n",
    "    return sum([p['correct'] for p in problems]) / len(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gsm_baseline():\n",
    "    prompt_template = baseline_utils.create_prompt_template(args.task)\n",
    "    llm = OpenAI(\n",
    "        model_name=args.model,\n",
    "        max_tokens=args.max_tokens,\n",
    "        stop=['\\\\n\\\\n', 'A:', 'Q:'],\n",
    "        temperature=args.temperature,\n",
    "        openai_api_key = os.getenv('OPEN_AI_API_KEY')\n",
    "  ) \n",
    "    for i in range(0, 1):\n",
    "        for variant in ['irc']:\n",
    "            data = baseline_utils.load_gsm_data(os.path.join(args.data_dir, f'gsmic_mixed_{i}_{variant}.jsonl'))\n",
    "            if (os.path.exists(os.path.join(args.save_dir, f'gsmic_mixed_{i}_{variant}_output_{args.model}.json')) \n",
    "                or os.path.exists(os.path.join(args.save_dir, f'hand_gsmic_mixed_{i}_{variant}_output_{args.model}.json'))):\n",
    "                continue\n",
    "            problems = await gsm_run(prompt_template, llm, data)\n",
    "            with open(os.path.join(args.save_dir, f'gsmic_mixed_{i}_{variant}_output_{args.model}.json'), 'w') as f:\n",
    "                  f.write(json.dumps(problems) + '\\n')\n",
    "            for p in problems:\n",
    "                print(p)\n",
    "                p['final_answer'] = baseline_utils.parse_answer(p['output'])\n",
    "                p['correct'] = p['final_answer'] == p['target']\n",
    "            with open(os.path.join(args.save_dir, f'gsmic_mixed_{i}_{variant}_output_{args.model}.json'), 'w') as f:\n",
    "                  f.write(json.dumps(problems) + '\\n')\n",
    "            logger.write(f'Accuracy for gsmic_mixed_{i}_{variant} = {calc_accuracy(problems)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dwang/anaconda3/envs/adversarial/lib/python3.11/site-packages/langchain/llms/openai.py:170: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/dwang/anaconda3/envs/adversarial/lib/python3.11/site-packages/langchain/llms/openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88056 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88055 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88054 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88055 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88052 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88055 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88056 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88057 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88006 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88005 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88006 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88005 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88003 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88003 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88001 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88002 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87999 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87996 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87992 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87986 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87986 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87985 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87985 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87986 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87988 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87986 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87981 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87978 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87980 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87978 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87978 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87979 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87981 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87979 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87980 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87977 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87977 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87977 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87975 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87976 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87976 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87975 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87977 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87975 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87971 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87972 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87969 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87972 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87970 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87970 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87968 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87951 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87893 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87891 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87882 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87877 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87868 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87869 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87867 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87866 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87872 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 87855 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='{\"work\": \"Michelle paid $2 for the ride fee and $2.5 per mile for 4 miles, so her total cost was $12.\", \"final_answer\": \"$12\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173710530> JSON: {\n",
      "  \"completion_tokens\": 39,\n",
      "  \"prompt_tokens\": 269,\n",
      "  \"total_tokens\": 308\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 1 rounds\n",
      "generations=[[Generation(text='The TV show was aired for 1.5 hours.\\nThe commercials lasted a total of 10 minutes x 3 = 30 minutes.\\nIn hours, the commercials lasted 30 minutes / 60 = 0.5 hours.\\nTherefore, the TV show itself, not counting commercials, lasted 1.5 hours - 0.5 hours = 1 hour.\\nThe final answer is 1 hour.', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1737130b0> JSON: {\n",
      "  \"completion_tokens\": 84,\n",
      "  \"prompt_tokens\": 264,\n",
      "  \"total_tokens\": 348\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 2 rounds\n",
      "generations=[[Generation(text='{\"work\": \"Helga tried on 7 pairs of shoes at the first store. At the second store, she tried on 2 more pairs than at the first store, which is 9 pairs of shoes. At the third store, she did not try on any shoes. At the fourth store, she tried on twice as many pairs of shoes as she did at all three other stores combined, which is 2*(7+9+0) = 52 pairs of shoes. Therefore, Helga tried on a total of 7+9+0+52 = 68 pairs of shoes before buying her new shoes.\", \"final_answer\": \"68\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173712c30> JSON: {\n",
      "  \"completion_tokens\": 135,\n",
      "  \"prompt_tokens\": 331,\n",
      "  \"total_tokens\": 466\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 3 rounds\n",
      "generations=[[Generation(text='{\"work\": \"Helga tried on 7 pairs of shoes at the first store. At the second store, she tried on 2 more pairs than at the first store, which is 9 pairs of shoes. At the third store, she did not try on any shoes. At the fourth store, she tried on twice as many pairs of shoes as she did at all three other stores combined, which is 2*(7+9+0)=32 pairs of shoes. Therefore, Helga tried on a total of 7+9+0+32=48 pairs of shoes.\", \"final_answer\": \"48\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173712b10> JSON: {\n",
      "  \"completion_tokens\": 127,\n",
      "  \"prompt_tokens\": 328,\n",
      "  \"total_tokens\": 455\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 4 rounds\n",
      "generations=[[Generation(text=\"First, we need to convert Steve's height to inches. Since 1 foot is equal to 12 inches, Steve's initial height in inches is 5 x 12 + 6 = 66 inches.\\nNext, we add the 6 inches that Steve grows, giving us a total height of 72 inches.\\nTherefore, Steve's final height is 72 inches.\", generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173713650> JSON: {\n",
      "  \"completion_tokens\": 76,\n",
      "  \"prompt_tokens\": 228,\n",
      "  \"total_tokens\": 304\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 5 rounds\n",
      "generations=[[Generation(text='Libby has 160 quarters in her piggy bank.\\nShe has to pay $35 to replace her sister\\'s dress.\\n35 dollars is equal to 140 quarters (1 dollar = 4 quarters).\\nSo, Libby will have 20 quarters left after replacing the dress.\\nLibby\\'s classmate bought 50 tomatoes from the grocery store, which is not relevant to the final answer.\\nTherefore, the final answer is:\\n```\\n{\\n  \"work\": \"Libby had 160 quarters, but had to pay 140 quarters to replace her sister\\'s dress. Therefore, she has 20 quarters left.\",\\n  \"final_answer\": \"20\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173713650> JSON: {\n",
      "  \"completion_tokens\": 134,\n",
      "  \"prompt_tokens\": 259,\n",
      "  \"total_tokens\": 393\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 6 rounds\n",
      "generations=[[Generation(text='{\"work\": \"Helga tried on 7 pairs of shoes at the first store. At the second store, she tried on 2 more pairs than at the first store, which is 9 pairs of shoes. At the third store, she did not try on any shoes, but she bought a scarf. At the fourth store, she tried on twice as many pairs of shoes as she did at all three other stores combined, which is 2*(7+9+0)=52 pairs of shoes. Therefore, Helga tried on a total of 7+9+52=68 pairs of shoes before buying her new shoes.\", \"final_answer\": \"68\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1737130b0> JSON: {\n",
      "  \"completion_tokens\": 136,\n",
      "  \"prompt_tokens\": 330,\n",
      "  \"total_tokens\": 466\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 7 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total number of sandwiches Sally eats over the weekend. This is 2 + 1 = 3 sandwiches.\\nNext, we need to calculate the total number of pieces of bread used by Sally over the weekend. Each sandwich uses 2 pieces of bread, so Sally uses 3 * 2 = 6 pieces of bread.\\nTherefore, the final answer is 6 pieces of bread.\\n{\\n  \"work\": \"Sally eats 2 sandwiches on Saturday and 1 sandwich on Sunday. Total sandwiches = 2 + 1 = 3. Each sandwich uses 2 pieces of bread, so total pieces of bread = 3 * 2 = 6.\",\\n  \"final_answer\": \"6\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1737112b0> JSON: {\n",
      "  \"completion_tokens\": 151,\n",
      "  \"prompt_tokens\": 251,\n",
      "  \"total_tokens\": 402\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 8 rounds\n",
      "generations=[[Generation(text='Luke needs to fill 4 bottles, which means he needs a total of 4 x 85 = 340 paper stars.\\nHe has already made 33 stars, so he still needs to make 340 - 33 = 307 more stars.\\nSince his neighbor can provide 10000 pieces of paper, Luke has enough resources to make the remaining stars.\\nTherefore, the final answer is 307. \\n\\nHere is the output in the required JSON format:\\n```\\n{\\n  \"work\": \"Luke needs to fill 4 bottles, which means he needs a total of 4 x 85 = 340 paper stars. He has already made 33 stars, so he still needs to make 340 - 33 = 307 more stars. Since his neighbor can provide 10000 pieces of paper, Luke has enough resources to make the remaining stars.\",\\n  \"final_answer\": \"307\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173712810> JSON: {\n",
      "  \"completion_tokens\": 184,\n",
      "  \"prompt_tokens\": 250,\n",
      "  \"total_tokens\": 434\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 9 rounds\n",
      "generations=[[Generation(text=\"First, we know that Jude sold 16 tickets. \\nAndrea sold twice as many tickets as Jude, so she sold 32 tickets. \\nHalf of Jude's tickets is 8, and 4 more than that is 12, so Sandra sold 12 tickets. \\nAndrea's brother sold 2000 more baseball tickets than Andrea, but we don't need that information to answer the question. \\n\\nIn total, Jude, Andrea, Sandra, and Andrea's brother sold 16 + 32 + 12 + (2000 + 32) = 2092 tickets. \\n\\nTherefore, 100 - 2092 = -1992 tickets need to be sold, which is not possible. This means there must be an error in the given information or calculations.\", generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1737130b0> JSON: {\n",
      "  \"completion_tokens\": 158,\n",
      "  \"prompt_tokens\": 266,\n",
      "  \"total_tokens\": 424\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 10 rounds\n",
      "generations=[[Generation(text='First, we need to find out how many students are enrolled in Statistics. We know that half of Mr. Angstadt\\'s 120 students are enrolled in Statistics, so:\\n\\n120 / 2 = 60 students in Statistics\\n\\nNext, we need to find out how many of those students are seniors. We know that 90% of the students in Statistics are seniors, so:\\n\\n60 * 0.9 = 54 seniors in Statistics\\n\\nTherefore, the final answer is that there are 54 seniors enrolled in Statistics. \\n\\nHere is the formatted output as a JSON instance that conforms to the given schema:\\n\\n```\\n{\\n  \"work\": \"First, we found that there are 60 students enrolled in Statistics by dividing the total number of students (120) by 2. Then, we multiplied the number of students in Statistics (60) by the percentage of seniors (90%) to find that there are 54 seniors enrolled in Statistics.\",\\n  \"final_answer\": \"54\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1737128d0> JSON: {\n",
      "  \"completion_tokens\": 201,\n",
      "  \"prompt_tokens\": 263,\n",
      "  \"total_tokens\": 464\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 11 rounds\n",
      "generations=[[Generation(text='First, we need to calculate how much Nathalie ate. One-eighth of 400 grams is 50 grams. \\n\\nNext, we need to calculate how much Pierre ate. Pierre ate double what Nathalie ate, so he ate 2 * 50 grams = 100 grams. \\n\\nSince Mary sold 4 cakes today, we need to multiply Pierre\\'s amount by 4 to get the total amount he ate. 4 * 100 grams = 400 grams. \\n\\nTherefore, Pierre ate 400 grams in total. \\n\\nHere is the well-formatted JSON instance for this answer: \\n\\n```\\n{\\n  \"work\": \"Nathalie ate 50 grams, Pierre ate 100 grams, and there were 4 cakes sold. Therefore, Pierre ate a total of 400 grams.\",\\n  \"final_answer\": \"400\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173713650> JSON: {\n",
      "  \"completion_tokens\": 172,\n",
      "  \"prompt_tokens\": 249,\n",
      "  \"total_tokens\": 421\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 12 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88556 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88550 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='First, we need to determine how many scoops of ice cream Oli has. We know that he has 4 scoops.\\n\\nNext, we need to determine how many scoops of ice cream Victoria has. We know that she has twice as many scoops as Oli. Therefore, Victoria has 8 scoops of ice cream.\\n\\nNow, we can calculate the difference between the number of scoops that Victoria has and the number of scoops that Oli has. Victoria has 4 more scoops of ice cream than Oli.\\n\\nTherefore, the final answer is 4. \\n\\n{\\n  \"work\": \"Oli has 4 scoops of ice cream and Victoria has twice as many scoops as Oli, which is 8 scoops. Therefore, the difference between the number of scoops that Victoria has and the number of scoops that Oli has is 4.\",\\n  \"final_answer\": \"4\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17341aed0> JSON: {\n",
      "  \"completion_tokens\": 191,\n",
      "  \"prompt_tokens\": 257,\n",
      "  \"total_tokens\": 448\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 13 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total number of pieces of popcorn that Jared\\'s three friends can eat:\\n3 friends * 60 pieces/friend = 180 pieces\\n\\nNext, we need to add up the total number of pieces of popcorn that everyone can eat:\\nJared + friends = 90 + 180 = 270 pieces\\n\\nThen, we need to divide the total number of pieces of popcorn by the number of pieces per serving to get the total number of servings:\\n270 pieces / 30 pieces/serving = 9 servings\\n\\nTherefore, Jared should order 9 servings of popcorn for everyone. \\n\\n{\"work\": \"To calculate the total number of servings of popcorn, we first need to calculate the total number of pieces of popcorn that Jared\\'s three friends can eat. We do this by multiplying the number of friends (3) by the number of pieces each friend can eat (60), which gives us a total of 180 pieces. Next, we add up the total number of pieces of popcorn that Jared and his friends can eat, which is 90 + 180 = 270 pieces. Finally, we divide the total number of pieces of popcorn by the number of pieces per serving (30) to get the total number of servings, which is 9 servings.\", \"final_answer\": \"9\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173418dd0> JSON: {\n",
      "  \"completion_tokens\": 265,\n",
      "  \"prompt_tokens\": 268,\n",
      "  \"total_tokens\": 533\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 14 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88525 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88525 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88523 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88520 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88518 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88520 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88516 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88515 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88515 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88513 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88510 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88513 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88507 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88505 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88502 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88503 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88501 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88499 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88489 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88485 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88482 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88479 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88473 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88473 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88426 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88397 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88398 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88399 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88397 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88394 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88388 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88384 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88383 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88382 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88383 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88382 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88382 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88381 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88379 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88381 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88381 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88378 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88379 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88376 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88378 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88378 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88375 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88371 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88366 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88369 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88367 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88369 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88366 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88368 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88365 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88363 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88358 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88361 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88357 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88351 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88339 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88337 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88329 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88329 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88328 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88331 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88318 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88288 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88279 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88276 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88259 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88256 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='First, we need to find out how many oranges Sandra has. We know that Sandra has 3 times as many oranges as Betty, who has 12 oranges. So Sandra has 3 * 12 = 36 oranges.\\n\\nNext, we need to find out how many oranges Emily has. We know that Emily has 7 times as many oranges as Sandra, who has 36 oranges. So Emily has 7 * 36 = 252 oranges.\\n\\nFinally, we need to add the 5 pineapples that Emily\\'s mother gave her to the total number of oranges Emily has. So Emily has 252 + 5 = 257 pieces of fruit in total.\\n\\n{\"work\": \"Sandra has 36 oranges (3 times Betty\\'s 12 oranges). Emily has 7 times as many oranges as Sandra, so she has 7 * 36 = 252 oranges. Emily\\'s mother gave her 5 pineapples, so she has 252 + 5 = 257 pieces of fruit in total.\", \"final_answer\": \"257\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365cbf0> JSON: {\n",
      "  \"completion_tokens\": 214,\n",
      "  \"prompt_tokens\": 248,\n",
      "  \"total_tokens\": 462\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 15 rounds\n",
      "generations=[[Generation(text='First, Jennifer has a total of 212 + 310 + 502 = 1024 sweets.\\nNext, she needs to share these sweets between herself and her 3 friends, which makes a total of 4 people.\\nTo find out how many sweets each person will get, we need to divide the total number of sweets by the number of people: 1024 / 4 = 256.\\nTherefore, Jennifer and her friends will each get 256 sweets.\\nAs for Emma\\'s lemons, they are not relevant to the question and can be ignored. \\n\\nHere is the formatted output:\\n```\\n{\\n    \"work\": \"Jennifer has a total of 212 + 310 + 502 = 1024 sweets. She needs to share these sweets between herself and her 3 friends, which makes a total of 4 people. To find out how many sweets each person will get, we need to divide the total number of sweets by the number of people: 1024 / 4 = 256.\",\\n    \"final_answer\": \"256\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365c830> JSON: {\n",
      "  \"completion_tokens\": 217,\n",
      "  \"prompt_tokens\": 250,\n",
      "  \"total_tokens\": 467\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 16 rounds\n",
      "generations=[[Generation(text='James has 2 trees with 20 plants each, so he has a total of 40 plants.\\nEach plant has 1 seed, so James has a total of 40 seeds.\\nJames plants 60% of those seeds, which is 0.6 * 40 = 24 seeds.\\nSince each plant comes from 1 seed, James planted 24 trees.\\nHowever, James\\' neighbor did not remove any trees, so James still has 2 trees. Therefore, James planted 24 - 2 = 22 trees. \\n\\nHere is the well-formatted instance of the schema:\\n```\\n{\\n  \"work\": \"James has 2 trees with 20 plants each, so he has a total of 40 plants. Each plant has 1 seed, so James has a total of 40 seeds. James plants 60% of those seeds, which is 0.6 * 40 = 24 seeds. Since each plant comes from 1 seed, James planted 24 trees. However, James\\' neighbor did not remove any trees, so James still has 2 trees. Therefore, James planted 24 - 2 = 22 trees.\",\\n  \"final_answer\": \"22\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365daf0> JSON: {\n",
      "  \"completion_tokens\": 248,\n",
      "  \"prompt_tokens\": 259,\n",
      "  \"total_tokens\": 507\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 17 rounds\n",
      "generations=[[Generation(text='{\"work\": \"Lucy starts with $65 in the bank. She made a $15 deposit and then followed by a $4 withdrawal.\", \"final_answer\": \"Lucy\\'s bank balance is $76.\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365c8f0> JSON: {\n",
      "  \"completion_tokens\": 44,\n",
      "  \"prompt_tokens\": 243,\n",
      "  \"total_tokens\": 287\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 18 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total number of M&Ms that Amy has. Since she has 7 times as many M&Ms as chocolate bars, and she has 5 chocolate bars, she has 7*5 = 35 M&Ms.\\n\\nNext, we need to calculate the total number of marshmallows that Amy has. Since she has 6 times as many marshmallows as M&Ms, and she has 35 M&Ms, she has 6*35 = 210 marshmallows.\\n\\nNow, we need to calculate the total number of candies that Amy has. She has 5 chocolate bars, 35 M&Ms, and 210 marshmallows, for a total of 5+35+210 = 250 candies.\\n\\nSince Jack\\'s height is 10 feet, we need to convert this to inches, which is 10*12 = 120 inches.\\n\\nFinally, we need to calculate the number of baskets that Amy can fill. Each basket has 10 candies, so the number of baskets is 250/10 = 25 baskets.\\n\\nTherefore, Amy can fill 25 baskets with candies for the car pool. \\n\\nHere is the output in JSON format:\\n```\\n{\\n  \"work\": \"5 chocolate bars + 35 M&Ms + 210 marshmallows = 250 candies. Jack\\'s height is 10 feet, which is 120 inches. 250 candies / 10 candies per basket = 25 baskets.\",\\n  \"final_answer\": \"25\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365c8f0> JSON: {\n",
      "  \"completion_tokens\": 313,\n",
      "  \"prompt_tokens\": 278,\n",
      "  \"total_tokens\": 591\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 19 rounds\n",
      "generations=[[Generation(text='First, Officer Hopps needs to determine how many tickets he has already given out in the first 15 days of May. To do this, he can multiply the average number of tickets he gives out per day (8) by the number of days he has worked so far (15): \\n\\n```\\nwork: \"15 days * 8 tickets/day = 120 tickets given out so far\"\\n```\\n\\nNext, he needs to determine how many tickets he still needs to give out to reach his goal of 200 tickets for the month. To do this, he can subtract the number of tickets he has already given out (120) from his goal (200): \\n\\n```\\nwork: \"200 tickets - 120 tickets = 80 tickets left to give out\"\\n```\\n\\nFinally, he needs to determine how many tickets he needs to give out each day for the rest of the month to reach his goal. To do this, he can divide the number of tickets he still needs to give out (80) by the number of days left in the month (16): \\n\\n```\\nfinal_answer: \"80 tickets / 16 days = 5 tickets/day\"\\n```\\n\\nTherefore, Officer Hopps needs to average 5 tickets per day for the rest of the month to reach his goal of 200 tickets. \\n\\nThe well-formatted JSON instance for this answer is:\\n\\n```\\n{\\n  \"work\": \"15 days * 8 tickets/day = 120 tickets given out so far\",\\n  \"final_answer\": \"80 tickets / 16 days = 5 tickets/day\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365e510> JSON: {\n",
      "  \"completion_tokens\": 321,\n",
      "  \"prompt_tokens\": 262,\n",
      "  \"total_tokens\": 583\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 20 rounds\n",
      "generations=[[Generation(text='{\"work\": \"Violet needs 800 ml of water per hour hiked and her dog needs 400 ml of water per hour. To calculate the total amount of water needed, we need to add the water needed for Violet and her dog. So, the total water needed per hour is 800 ml + 400 ml = 1200 ml. To convert this to liters, we divide by 1000, which gives us 1.2 L per hour. We know that Violet can carry 4.8 L of water, so we can calculate how many hours she and her dog can spend hiking by dividing the total amount of water by the water needed per hour. So, 4.8 L / 1.2 L per hour = 4 hours.\", \"final_answer\": \"4\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365c4d0> JSON: {\n",
      "  \"completion_tokens\": 165,\n",
      "  \"prompt_tokens\": 269,\n",
      "  \"total_tokens\": 434\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 21 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total number of pieces of popcorn that Jared and his friends can eat. Jared can eat 90 pieces and his three friends can each eat 60 pieces, so the total is:\\n\\n90 + (3 * 60) = 270\\n\\nNext, we need to calculate how many servings of popcorn are needed. Each serving has 30 pieces of popcorn, so we can divide the total number of pieces by 30:\\n\\n270 / 30 = 9\\n\\nTherefore, Jared should order 9 servings of popcorn for all of them.\\n\\nHere is the formatted output in JSON:\\n\\n```\\n{\\n  \"work\": \"To calculate the total number of pieces of popcorn that Jared and his friends can eat, we add Jared\\'s 90 pieces to his three friends\\' 60 pieces each, for a total of 270 pieces of popcorn. Then, we divide the total number of pieces by 30 to get the number of servings needed. The final answer is 9 servings.\",\\n  \"final_answer\": \"9\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17365e2d0> JSON: {\n",
      "  \"completion_tokens\": 212,\n",
      "  \"prompt_tokens\": 257,\n",
      "  \"total_tokens\": 469\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 22 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89078 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89073 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89072 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89071 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89070 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89065 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89061 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89065 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89058 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89060 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89057 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89059 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89059 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89061 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89060 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89054 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89052 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89050 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89046 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89051 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89049 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89046 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89040 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89004 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88964 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88960 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88958 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88953 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88948 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88953 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88946 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88950 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88943 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88943 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88944 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88943 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88941 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88940 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88942 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88937 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88930 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88937 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88926 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88923 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88924 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88924 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88922 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88920 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88915 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88898 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88900 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88902 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88900 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88897 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88892 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88894 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88907 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88890 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88882 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88877 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88865 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88858 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88856 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88853 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88855 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88855 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88866 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88856 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88852 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88850 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88850 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88841 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88845 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88833 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88826 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='{\"work\": \"Anna used 4 baking trays, each with 20 cupcakes, for a total of 80 cupcakes. She sold 3/5 of them, which is 48 cupcakes. Her brother\\'s oven can hold 10000 trays, so she could potentially make 800000 cupcakes. However, she only made 48, so she earned $96 from selling them.\", \"final_answer\": \"96\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173712270> JSON: {\n",
      "  \"completion_tokens\": 85,\n",
      "  \"prompt_tokens\": 267,\n",
      "  \"total_tokens\": 352\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 23 rounds\n",
      "generations=[[Generation(text='First, Kelly harvested a total of 55 + 101 + 78 = 234 carrots.\\nNext, we need to convert the number of carrots to pounds by dividing by 6: 234 / 6 = 39 pounds.\\nTherefore, Kelly harvested 39 pounds of carrots.\\n{\\n  \"work\": \"Kelly harvested a total of 55 + 101 + 78 = 234 carrots. Next, we need to convert the number of carrots to pounds by dividing by 6: 234 / 6 = 39 pounds.\",\\n  \"final_answer\": \"39\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x1733ca510> JSON: {\n",
      "  \"completion_tokens\": 119,\n",
      "  \"prompt_tokens\": 280,\n",
      "  \"total_tokens\": 399\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 24 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89601 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89603 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89595 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89584 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89582 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89572 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89575 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89568 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89568 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89574 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89563 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89557 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89557 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89558 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89549 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89550 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89505 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89490 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89492 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89490 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89465 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89469 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89438 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89438 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89422 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89422 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89419 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89411 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89379 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89373 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89373 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89376 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89325 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89322 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89265 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89221 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='{\\n  \"work\": \"Rose needs to add up the cost of the paintbrush, paints, and easel.\",\\n  \"final_answer\": \"Rose needs $11.00 more.\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17371e1b0> JSON: {\n",
      "  \"completion_tokens\": 39,\n",
      "  \"prompt_tokens\": 274,\n",
      "  \"total_tokens\": 313\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 25 rounds\n",
      "generations=[[Generation(text='Abie had 20 bags of chips.\\nAbie gave 4 bags to her friend.\\nAbie bought 6 more bags of chips.\\nAbie\\'s mother has 10 packets of candies.\\nTo find out how many bags of chips Abie has in the end, we need to subtract the bags she gave away and add the bags she bought.\\n20 - 4 + 6 = 22\\nAbie has 22 bags of chips in the end.\\n\\n{\"work\": \"20 - 4 + 6 = 22\", \"final_answer\": \"22\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17371e1b0> JSON: {\n",
      "  \"completion_tokens\": 116,\n",
      "  \"prompt_tokens\": 254,\n",
      "  \"total_tokens\": 370\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 26 rounds\n",
      "generations=[[Generation(text='First, we need to find out how many cookies Uncle Jude gave to Anna. He gave 15 cookies to Tim and 23 cookies to Mike, so he gave a total of 15 + 23 = 38 cookies to them. If he gave twice as many cookies to Anna as he gave to Tim, then he gave 2 * 15 = 30 cookies to Anna. Therefore, he gave a total of 38 + 30 = 68 cookies to Tim, Mike, and Anna.\\n\\nWe know that Uncle Jude baked 256 cookies in total, so to find out how many cookies he put in the fridge, we need to subtract the number of cookies he gave away. 256 - 68 = 188 cookies were put in the fridge.\\n\\nNow, we need to find out how many pieces of bread Ada baked. Ada baked 10000 pieces of breads, which is not relevant to the question, so we can ignore this information.\\n\\nTherefore, the final answer is that Uncle Jude put 188 cookies in the fridge. \\n\\nHere is the formatted output:\\n```\\n{\\n  \"work\": \"Uncle Jude gave 15 cookies to Tim and 23 cookies to Mike, so he gave a total of 15 + 23 = 38 cookies to them. If he gave twice as many cookies to Anna as he gave to Tim, then he gave 2 * 15 = 30 cookies to Anna. Therefore, he gave a total of 38 + 30 = 68 cookies to Tim, Mike, and Anna. We know that Uncle Jude baked 256 cookies in total, so to find out how many cookies he put in the fridge, we need to subtract the number of cookies he gave away. 256 - 68 = 188 cookies were put in the fridge.\",\\n  \"final_answer\": \"188\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17371d790> JSON: {\n",
      "  \"completion_tokens\": 376,\n",
      "  \"prompt_tokens\": 268,\n",
      "  \"total_tokens\": 644\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 27 rounds\n",
      "generations=[[Generation(text='First, we need to find the total number of computers sold by Mr. Lu\\'s store. We know that half of the sales are laptops and one-third are netbooks, so we can calculate the number of desktop computers as follows:\\n\\n- Laptops: 72 / 2 = 36\\n- Netbooks: 72 / 3 = 24\\n- Desktops: 72 - 36 - 24 = 12\\n\\nTherefore, Mr. Lu\\'s store sold 12 desktop computers last month. \\n\\nTo summarize:\\n\\n```\\n{\\n  \"work\": \"Half of the sales are laptops, one-third are netbooks, and the rest are desktop computers. Therefore, the number of desktop computers sold can be calculated as follows: Desktops = Total sales - Laptops - Netbooks = 72 - 36 - 24 = 12\",\\n  \"final_answer\": \"12\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17371d790> JSON: {\n",
      "  \"completion_tokens\": 184,\n",
      "  \"prompt_tokens\": 275,\n",
      "  \"total_tokens\": 459\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 28 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88670 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88667 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88670 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88666 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88668 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88668 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88667 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88666 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88665 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88664 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88660 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88660 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88657 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88645 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88644 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88644 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88629 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88598 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88591 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88589 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88590 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88587 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88591 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88583 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88566 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88566 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88562 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88556 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88553 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88548 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88548 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88549 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88549 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88544 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88543 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88545 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88541 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88531 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88530 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88528 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88531 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88530 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88527 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88526 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88518 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88516 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88511 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88469 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88468 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88466 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88465 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88463 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88466 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88465 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88457 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88452 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88452 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88435 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88425 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88425 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88424 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88426 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88420 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88420 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88401 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88370 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 88323 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='{\"work\": \"Jennifer has a total of 1024 sweets (212 + 310 + 502). She wants to share them equally between herself and her 3 friends, which makes a total of 4 people. To find out how many sweets each person will get, we need to divide the total number of sweets by the number of people: 1024  4 = 256. Therefore, Jennifer and her friends will each get 256 sweets.\", \"final_answer\": \"256\"}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173539f10> JSON: {\n",
      "  \"completion_tokens\": 102,\n",
      "  \"prompt_tokens\": 255,\n",
      "  \"total_tokens\": 357\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 29 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total number of bicycle wheels in the garage. Since there are 4 bicycles and each bicycle has 2 wheels, there are a total of 8 wheels in the garage.\\n\\nNext, we need to calculate the total number of spokes. Since each wheel has 10 spokes, the total number of spokes in the garage is 8 * 10 = 80 spokes.\\n\\nTherefore, there are 80 spokes inside the garage.\\n\\n{\\n  \"work\": \"Total number of bicycle wheels in the garage is 8. Total number of spokes is 8 * 10 = 80.\",\\n  \"final_answer\": \"80\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173538a70> JSON: {\n",
      "  \"completion_tokens\": 133,\n",
      "  \"prompt_tokens\": 256,\n",
      "  \"total_tokens\": 389\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 30 rounds\n",
      "generations=[[Generation(text='First, we need to calculate the total cost of the items Zachary wants to buy. \\n\\nFootball: $3.75 \\nShorts: $2.40 \\nFootball shoes: $11.85 \\n\\nTotal cost: $3.75 + $2.40 + $11.85 = $18 \\n\\nNext, we need to subtract the total cost from the amount of money Zachary has. \\n\\nZachary has $10. \\n\\n$10 - $18 = -$8 \\n\\nSince the result is negative, it means that Zachary needs $8 more to buy all the items he wants. \\n\\nTherefore, the final answer is $8. \\n\\n{\\n  \"work\": \"Football: $3.75, Shorts: $2.40, Football shoes: $11.85. Total cost: $3.75 + $2.40 + $11.85 = $18. Zachary has $10. $10 - $18 = -$8. Zachary needs $8 more.\",\\n  \"final_answer\": \"8\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x17353a210> JSON: {\n",
      "  \"completion_tokens\": 213,\n",
      "  \"prompt_tokens\": 278,\n",
      "  \"total_tokens\": 491\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 31 rounds\n",
      "generations=[[Generation(text='First, we need to find out how many scoops of ice cream Oli has. Oli has 4 scoops of ice cream.\\n\\nNext, we need to find out how many scoops of ice cream Victoria has. Victoria has twice more scoops of ice cream than Oli\\'s. This means Victoria has 2 * 4 = 8 scoops of ice cream.\\n\\nFinally, we need to find out how many more scoops of ice cream Victoria has than Oli. To do this, we subtract the number of scoops Oli has from the number of scoops Victoria has. Victoria has 8 - 4 = 4 more scoops of ice cream than Oli.\\n\\nTherefore, the final answer is 4. \\n\\n{\\n    \"work\": \"Oli has 4 scoops of ice cream. Victoria has twice more scoops of ice cream than Oli\\'s, which is 8 scoops. To find out how many more scoops of ice cream Victoria has than Oli, we subtract the number of scoops Oli has from the number of scoops Victoria has. Victoria has 8 - 4 = 4 more scoops of ice cream than Oli.\",\\n    \"final_answer\": \"4\"\\n}', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173538a70> JSON: {\n",
      "  \"completion_tokens\": 255,\n",
      "  \"prompt_tokens\": 254,\n",
      "  \"total_tokens\": 509\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 32 rounds\n",
      "generations=[[Generation(text='First, we need to calculate how many inches of gift wrapper are used per 2 boxes:\\n18 inches/gift box * 2 gift boxes = 36 inches\\n\\nNext, we need to calculate how many gift boxes can be wrapped with 90 inches of gift wrapper per day:\\n90 inches / 36 inches/gift box = 2.5 gift boxes\\n\\nFinally, we need to calculate how many gift boxes can be wrapped every 3 days:\\n2.5 gift boxes/day * 3 days = 7.5 gift boxes\\n\\nTherefore, Edmund will be able to wrap 7.5 gift boxes every 3 days. \\n\\nHere is the output in the required JSON format:\\n```\\n{\\n  \"work\": \"To calculate the number of gift boxes Edmund can wrap every 3 days, we first need to calculate how many gift boxes can be wrapped with 90 inches of gift wrapper per day. We know that Edmund uses 18 inches of gift wrapper per gift box and on average, Tom sells 2 boxes every day. So, 18 inches/gift box * 2 gift boxes = 36 inches of gift wrapper are used per 2 boxes. Therefore, 90 inches / 36 inches/gift box = 2.5 gift boxes can be wrapped with 90 inches of gift wrapper per day. Finally, to calculate how many gift boxes can be wrapped every 3 days, we multiply 2.5 gift boxes/day by 3 days, which gives us 7.5 gift boxes.\",\\n  \"final_answer\": \"7.5\"\\n}\\n```', generation_info=None)]] llm_output={'token_usage': <OpenAIObject at 0x173538a70> JSON: {\n",
      "  \"completion_tokens\": 322,\n",
      "  \"prompt_tokens\": 258,\n",
      "  \"total_tokens\": 580\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n",
      "Completed 33 rounds\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89410 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89404 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89404 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89405 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89357 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-UL2nM4hjGA7CzFPYucOtFrPC on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "API server overloaded. Waiting for 30 seconds...\n"
     ]
    }
   ],
   "source": [
    "await gsm_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        problems = json.load(f)\n",
    "    for p in problems:\n",
    "        if (p['target'] == p['final_answer']):\n",
    "            p['correct'] = True\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(json.dumps(problems) + '\\n')\n",
    "    print(calc_accuracy(problems))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade(os.path.join(args.save_dir, f'gsmic_mixed_0_original_output_{args.model}.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
